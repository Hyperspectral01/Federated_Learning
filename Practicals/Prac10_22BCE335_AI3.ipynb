{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a900f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import math, random\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import label, find_objects\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "\n",
    "###################################################### MODEL ########################################3\n",
    "class sample_CNN_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "      super(sample_CNN_model, self).__init__()\n",
    "\n",
    "      # Load the pretrained ResNet18 model\n",
    "      self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "      # Ensure all layers require gradients\n",
    "      for param in self.model.parameters():\n",
    "          param.requires_grad = True\n",
    "\n",
    "      # Modify the final fully connected layer\n",
    "      num_features = self.model.fc.in_features\n",
    "      self.model.fc = nn.Linear(num_features, 4, bias=True)\n",
    "\n",
    "      # Initialize the new layer's weights\n",
    "      # nn.init.kaiming_normal_(self.model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "      nn.init.xavier_uniform_(self.model.fc.weight)  # For the final fully connected layer\n",
    "      self.model.fc.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "############################################ CUSTOM DATASET ##########################\n",
    "class custom_dataset():\n",
    "    def __init__(self,folder_path=None,transform=None):\n",
    "        self.image_paths=[]\n",
    "        self.output_classes=[]\n",
    "        self.transform=transform\n",
    "        if (folder_path!=None):\n",
    "            for categories in os.listdir(folder_path):\n",
    "              for image_name in os.listdir(os.path.join(folder_path,categories)):\n",
    "                self.image_paths.append(os.path.join(folder_path,categories,image_name))\n",
    "                if (categories==\"Diverticulosis\"):\n",
    "                  self.output_classes.append(0)\n",
    "                elif (categories==\"Neoplasm\"):\n",
    "                  self.output_classes.append(1)\n",
    "                elif (categories==\"Peritonitis\"):\n",
    "                  self.output_classes.append(2)\n",
    "                else:\n",
    "                  self.output_classes.append(3)\n",
    "\n",
    "            # # Zip the lists together and convert to a list of pairs\n",
    "            # combined = list(zip(self.image_paths, self.output_classes))\n",
    "\n",
    "            # # Shuffle the combined list\n",
    "            # random.shuffle(combined)\n",
    "\n",
    "            # # Unzip the combined s back into two lists\n",
    "            # self.image_paths, self.output_classes = zip(*combined)\n",
    "\n",
    "            # # Convert back to list type\n",
    "            # self.image_paths = list(self.image_paths)\n",
    "            # self.output_classes = list(self.output_classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "    # def bias_field_correction(self, channel_np):\n",
    "    #     \"\"\"\n",
    "    #     Apply bias field correction to a single-channel image.\n",
    "    #     \"\"\"\n",
    "    #     sitk_image = sitk.GetImageFromArray(channel_np)\n",
    "    #     # Create a mask using Otsu thresholding\n",
    "    #     mask = sitk.OtsuThreshold(sitk_image, 0, 1, 200)\n",
    "    #     corrected = sitk.N4BiasFieldCorrection(sitk_image, mask)\n",
    "    #     corrected_np = sitk.GetArrayFromImage(corrected)\n",
    "    #     return corrected_np\n",
    "\n",
    "    # def crop_to_white_blob(self, image_np):\n",
    "    #     \"\"\"\n",
    "    #     Crop the image to the bounding box of the connected component \n",
    "    #     (from the white blob) that contains the center of the image.\n",
    "    #     \"\"\"\n",
    "    #     # Convert first three channels (RGB) to grayscale by averaging\n",
    "    #     gray = np.mean(image_np[:, :, :3], axis=2)\n",
    "    #     # Create a binary mask; adjust threshold as needed for your data\n",
    "    #     binary = gray > 200\n",
    "\n",
    "    #     # Label connected regions and find bounding boxes\n",
    "    #     labeled, num_features = label(binary)\n",
    "    #     center_y, center_x = gray.shape[0] // 2, gray.shape[1] // 2\n",
    "    #     selected_bbox = None\n",
    "    #     objects = find_objects(labeled)\n",
    "    #     for i, slice_tuple in enumerate(objects, start=1):\n",
    "    #         y_slice, x_slice = slice_tuple\n",
    "    #         # Check if the image center lies within the component's bounding box\n",
    "    #         if (y_slice.start <= center_y < y_slice.stop) and (x_slice.start <= center_x < x_slice.stop):\n",
    "    #             selected_bbox = slice_tuple\n",
    "    #             break\n",
    "\n",
    "    #     if selected_bbox is not None:\n",
    "    #         y_slice, x_slice = selected_bbox\n",
    "    #         cropped = image_np[y_slice, x_slice, :]\n",
    "    #         return cropped\n",
    "    #     else:\n",
    "    #         # If no white blob is detected near the center, return the original image\n",
    "    #         return image_np\n",
    "\n",
    "    # def zscore_normalize(self, image_np):\n",
    "    #     \"\"\"\n",
    "    #     Apply per-channel z-score normalization.\n",
    "    #     \"\"\"\n",
    "    #     # Process each channel independently\n",
    "    #     for c in range(image_np.shape[2]):\n",
    "    #         channel = image_np[:, :, c]\n",
    "    #         mean = channel.mean()\n",
    "    #         std = channel.std()\n",
    "    #         if std > 0:\n",
    "    #             image_np[:, :, c] = (channel - mean) / std\n",
    "    #         else:\n",
    "    #             image_np[:, :, c] = channel - mean\n",
    "    #     return image_np\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the preprocessed image (assumed to already have the desired size and channels)\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        \n",
    "        # Optionally apply additional transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Convert image to a numpy array and then to a torch tensor with shape (C, H, W)\n",
    "            image_np = np.array(image)\n",
    "            image = torch.from_numpy(image_np.transpose(2, 0, 1))\n",
    "        \n",
    "        return image, self.output_classes[idx]\n",
    "\n",
    "\n",
    "    def take_out_items(self, ratio):\n",
    "\n",
    "        indices_label0 = [i for i, label in enumerate(self.output_classes) if label == 0]\n",
    "        indices_label1 = [i for i, label in enumerate(self.output_classes) if label == 1]\n",
    "        indices_label2 = [i for i, label in enumerate(self.output_classes) if label == 2]\n",
    "        indices_label3 = [i for i, label in enumerate(self.output_classes) if label == 3]\n",
    "\n",
    "        num_to_remove_0 = math.floor(len(indices_label0) * ratio)\n",
    "        num_to_remove_1 = math.floor(len(indices_label1) * ratio)\n",
    "        num_to_remove_2 = math.floor(len(indices_label2) * ratio)\n",
    "        num_to_remove_3 = math.floor(len(indices_label3) * ratio)\n",
    "\n",
    "        selected_indices_0 = random.sample(indices_label0, num_to_remove_0) if num_to_remove_0 > 0 else []\n",
    "        selected_indices_1 = random.sample(indices_label1, num_to_remove_1) if num_to_remove_1 > 0 else []\n",
    "        selected_indices_2 = random.sample(indices_label2, num_to_remove_2) if num_to_remove_2 > 0 else []\n",
    "        selected_indices_3 = random.sample(indices_label3, num_to_remove_3) if num_to_remove_3 > 0 else []\n",
    "\n",
    "        selected_indices = set(selected_indices_0 + selected_indices_1 + selected_indices_2 + selected_indices_3)\n",
    "\n",
    "        removed_image_paths = [self.image_paths[i] for i in selected_indices]\n",
    "        removed_labels = [self.output_classes[i] for i in selected_indices]\n",
    "\n",
    "        new_image_paths = []\n",
    "        new_output_classes = []\n",
    "        for idx, (img_path, label) in enumerate(zip(self.image_paths, self.output_classes)):\n",
    "            if idx not in selected_indices:\n",
    "                new_image_paths.append(img_path)\n",
    "                new_output_classes.append(label)\n",
    "\n",
    "        self.image_paths = new_image_paths\n",
    "        self.output_classes = new_output_classes\n",
    "\n",
    "        return removed_image_paths, removed_labels\n",
    "\n",
    "    def add_items(self, list_of_image_paths,list_of_labels):\n",
    "        self.image_paths.extend(list_of_image_paths)\n",
    "        self.output_classes.extend(list_of_labels)\n",
    "\n",
    "\n",
    "\n",
    "############################################## MAIN CODE ##############################################################\n",
    "\n",
    "# ====================== METRICS & PLOTTING ======================\n",
    "def test_global_model(global_model, test_dataloader):\n",
    "    \"\"\"Returns test loss, accuracy, precision, recall, F1\"\"\"\n",
    "    global_model.eval()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(test_dataloader):\n",
    "            outputs = global_model(images)\n",
    "            # print(\"OUTPUTS:\")\n",
    "            # print(outputs)\n",
    "            # print(\"LABELS:\")\n",
    "            # print(labels)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    # print(\"The Accuracy of local model after training: \",accuracy)\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def plot_learning_curves(metrics_history, hyperparams):\n",
    "    \"\"\"Plots metrics vs communication rounds for a single hyperparameter configuration\"\"\"\n",
    "    rounds = list(range(1, len(metrics_history['loss'])+1))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.suptitle(f\"Test Ratio: {hyperparams['test_ratio']} | Batch Size: {hyperparams['batch_size']}\\n\"\n",
    "                 f\"Rounds: {hyperparams['num_rounds']} | Epochs: {hyperparams['num_epochs']} | LR: {hyperparams['learning_rate']}\", \n",
    "                 y=1.02)\n",
    "    \n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall', 'f1']\n",
    "    titles = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles), 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        plt.plot(rounds, metrics_history[metric], marker='o')\n",
    "        plt.xlabel('Communication Round')\n",
    "        plt.ylabel(title)\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./out/learning_curves_ratio_{hyperparams['test_ratio']}_bs_{hyperparams['batch_size']}_rounds_{hyperparams['num_rounds']}_epochs_{hyperparams['num_epochs']}_lr_{hyperparams['learning_rate']}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_hyperparameter_comparisons(all_results):\n",
    "    \"\"\"Generates plots comparing metrics across different hyperparameters\"\"\"\n",
    "    hyperparams = ['test_ratio', 'batch_size', 'num_rounds', 'num_epochs', 'learning_rate']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'loss']\n",
    "    \n",
    "    for hp in hyperparams:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for metric in metrics:\n",
    "            x = [res['hyperparams'][hp] for res in all_results]\n",
    "            y = [res['final_'+metric] for res in all_results]\n",
    "            plt.scatter(x, y, label=metric, alpha=0.6)\n",
    "        \n",
    "        plt.xlabel(hp)\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.title(f'Impact of {hp} on Metrics')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"./out/hyperparam_{hp}_comparison.png\")\n",
    "        plt.close()\n",
    "\n",
    "# ====================== FEDERATED LEARNING CORE ======================\n",
    "def train_local_model(global_model, num_epochs, train_dataloader, test_dataloader, learning_rate):\n",
    "\n",
    "    print(\"############### LOCAL MODEL LOGS ############\")\n",
    "    local_model = copy.deepcopy(global_model)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(local_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Use a learning rate scheduler to prevent getting stuck\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "      optimizer, max_lr=0.001, \n",
    "      steps_per_epoch=len(train_dataloader), epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    local_model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        for images, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(images)\n",
    "            #target_onehot = F.one_hot(labels, num_classes=4).float()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "\n",
    "        val_loss, val_acc, _, _, _ = test_global_model(local_model, test_dataloader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    avg_loss, accuracy, precision, recall, f1=test_global_model(local_model,test_dataloader)\n",
    "    print(\"After_Training Local Model:\")\n",
    "    print(\"avg_loss: \",avg_loss)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    \n",
    "    return local_model.state_dict()\n",
    "\n",
    "def federated_learning_algo(model, train_dataloaders, test_dataloader, num_rounds, num_epochs, learning_rate, hyperparams):\n",
    "    global_model = copy.deepcopy(model)\n",
    "    total_clients = len(train_dataloaders)\n",
    "    total_batches_across_dataloaders=sum([len(train_dataloader) for train_dataloader in train_dataloaders])\n",
    "    print(\"Total Number of batches across dataloaders: \",total_batches_across_dataloaders)\n",
    "    metrics_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    \n",
    "    print(f\"\\n=== Starting Training with: Test Ratio={hyperparams['test_ratio']}, Batch Size={hyperparams['batch_size']}, \"\n",
    "          f\"Rounds={num_rounds}, Epochs={num_epochs}, LR={learning_rate} ===\")\n",
    "\n",
    "    client_optimizers = [\n",
    "        torch.optim.Adam(global_model.parameters(), lr=learning_rate)\n",
    "        for _ in range(len(train_dataloaders))\n",
    "    ]\n",
    "    \n",
    "    for round in range(1, num_rounds+1):\n",
    "        print(f\"\\nRound {round}/{num_rounds}:\")\n",
    "        \n",
    "        # Local Training\n",
    "        client_weights = []\n",
    "        for client_id, (dataloader, optimizer) in enumerate(zip(train_dataloaders, client_optimizers), 1):\n",
    "            print(f\"  Client {client_id} training...\", end='\\r')\n",
    "            weights = train_local_model(global_model, num_epochs, dataloader, test_dataloader, learning_rate)\n",
    "            client_weights.append(weights)\n",
    "        \n",
    "        # Aggregation (Federated Averaging)\n",
    "        global_weights = {}\n",
    "        for key in client_weights[0].keys():\n",
    "            for client, train_dataloader in zip(client_weights, train_dataloaders):\n",
    "                if (key not in global_weights.keys()):\n",
    "                    global_weights[key] = (len(train_dataloader)/total_batches_across_dataloaders)*client[key]\n",
    "                    # print(\"ratio: \",(len(train_dataloader)/total_batches_across_dataloaders))\n",
    "                else:\n",
    "                    global_weights[key] += (len(train_dataloader)/total_batches_across_dataloaders)*client[key]                \n",
    "                    # print(\"ratio: \",(len(train_dataloader)/total_batches_across_dataloaders))\n",
    "                    \n",
    "        global_model.load_state_dict(global_weights)\n",
    "        \n",
    "        # Testing\n",
    "        test_loss, acc, prec, rec, f1 = test_global_model(global_model, test_dataloader)\n",
    "        metrics_history['loss'].append(test_loss)\n",
    "        metrics_history['accuracy'].append(acc)\n",
    "        metrics_history['precision'].append(prec)\n",
    "        metrics_history['recall'].append(rec)\n",
    "        metrics_history['f1'].append(f1)\n",
    "\n",
    "        print(\"############## GLOBAL MODEL LOGS ##############\")\n",
    "        print(f\"  Round {round} Metrics - Loss: {test_loss:.4f} | Accuracy: {acc:.4f} | \"\n",
    "              f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}       \")\n",
    "    \n",
    "    # Save learning curves for this configuration\n",
    "    plot_learning_curves(metrics_history, hyperparams)\n",
    "\n",
    "    torch.save(global_model,\"./out/\"+str(hyperparams[\"test_ratio\"])+\"_\"+str(hyperparams[\"batch_size\"])+\"_\"+str(hyperparams[\"num_rounds\"])+\"_\"+str(hyperparams[\"num_epochs\"])+\"_\"+str(hyperparams[\"learning_rate\"])+\".pth\")\n",
    "    torch.save(global_model.state_dict(),\"./out/\"+str(hyperparams[\"test_ratio\"])+\"_\"+str(hyperparams[\"batch_size\"])+\"_\"+str(hyperparams[\"num_rounds\"])+\"_\"+str(hyperparams[\"num_epochs\"])+\"_\"+str(hyperparams[\"learning_rate\"])+\"_state_dict.pth\")\n",
    "    \n",
    "    # Return final metrics for hyperparameter comparison\n",
    "    return {\n",
    "        'hyperparams': hyperparams,\n",
    "        'final_accuracy': metrics_history['accuracy'][-1],\n",
    "        'final_precision': metrics_history['precision'][-1],\n",
    "        'final_recall': metrics_history['recall'][-1],\n",
    "        'final_f1': metrics_history['f1'][-1],\n",
    "        'final_loss': metrics_history['loss'][-1]\n",
    "    }\n",
    "\n",
    "# ====================== MAIN EXECUTION ======================\n",
    "\n",
    "    \n",
    "# Assume model and datasets are predefined\n",
    "model = sample_CNN_model()  # Your model definition\n",
    "\n",
    "assert all(p.requires_grad for p in model.parameters()), \"Some weights have requires_grad=False\"\n",
    "\n",
    "# For training data (with augmentations)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# For validation/test data (no augmentations)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "center_datasets = [custom_dataset(folder_path=\"Center_1\",transform=train_transforms),custom_dataset(folder_path=\"Center_2\",transform=train_transforms), custom_dataset(folder_path=\"Center_3\",transform=train_transforms), custom_dataset(folder_path=\"Center_4\",transform=train_transforms)]  # Your central datasets\n",
    "\n",
    "# Hyperparameter Search Space\n",
    "test_ratios = [0.2,0.3,0.4]\n",
    "batch_sizes = [100]\n",
    "num_rounds_list = [8]\n",
    "num_epochs_list = [3]\n",
    "learning_rates = [0.001] #,0.00007,0.0001,0.0007\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    \n",
    "    # Dataset preparation\n",
    "    to_put_image_paths=[]\n",
    "    to_put_image_labels=[]\n",
    "    for center_dataset in center_datasets:\n",
    "        to_append_image_paths,to_append_image_labels=center_dataset.take_out_items(test_ratio)\n",
    "        to_put_image_paths.extend(to_append_image_paths)\n",
    "        to_put_image_labels.extend(to_append_image_labels)\n",
    "    test_dataset=custom_dataset(transform=test_transforms)#Here the folder path is None so that it makes an empty dataset\n",
    "    test_dataset.add_items(to_put_image_paths,to_put_image_labels)\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        train_dataloaders = [DataLoader(center_dataset, batch_size=batch_size,shuffle=True) for center_dataset in center_datasets]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n",
    "        \n",
    "        for num_rounds in num_rounds_list:\n",
    "            for num_epochs in num_epochs_list:\n",
    "                for lr in learning_rates:\n",
    "                    hyperparams = {\n",
    "                        'test_ratio': test_ratio,\n",
    "                        'batch_size': batch_size,\n",
    "                        'num_rounds': num_rounds,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'learning_rate': lr\n",
    "                    }\n",
    "                    \n",
    "                    # Run federated learning\n",
    "                    result = federated_learning_algo(\n",
    "                        model, train_dataloaders, test_dataloader, \n",
    "                        num_rounds, num_epochs, lr, hyperparams\n",
    "                    )\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "\n",
    "# Generate hyperparameter comparison plots\n",
    "plot_hyperparameter_comparisons(all_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
