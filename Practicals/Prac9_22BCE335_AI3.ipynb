{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6424aaa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:29.727442Z",
     "iopub.status.busy": "2025-04-08T03:41:29.727109Z",
     "iopub.status.idle": "2025-04-08T03:41:35.359729Z",
     "shell.execute_reply": "2025-04-08T03:41:35.358480Z"
    },
    "papermill": {
     "duration": 5.638648,
     "end_time": "2025-04-08T03:41:35.361526",
     "exception": false,
     "start_time": "2025-04-08T03:41:29.722878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad22f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:35.368627Z",
     "iopub.status.busy": "2025-04-08T03:41:35.368276Z",
     "iopub.status.idle": "2025-04-08T03:41:39.429959Z",
     "shell.execute_reply": "2025-04-08T03:41:39.428680Z"
    },
    "papermill": {
     "duration": 4.068269,
     "end_time": "2025-04-08T03:41:39.433015",
     "exception": false,
     "start_time": "2025-04-08T03:41:35.364746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.4.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34e651f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:39.444141Z",
     "iopub.status.busy": "2025-04-08T03:41:39.443769Z",
     "iopub.status.idle": "2025-04-08T03:41:43.495860Z",
     "shell.execute_reply": "2025-04-08T03:41:43.494635Z"
    },
    "papermill": {
     "duration": 4.059799,
     "end_time": "2025-04-08T03:41:43.497880",
     "exception": false,
     "start_time": "2025-04-08T03:41:39.438081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\r\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118e6c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:43.505250Z",
     "iopub.status.busy": "2025-04-08T03:41:43.504916Z",
     "iopub.status.idle": "2025-04-08T03:41:55.601927Z",
     "shell.execute_reply": "2025-04-08T03:41:55.601055Z"
    },
    "papermill": {
     "duration": 12.102757,
     "end_time": "2025-04-08T03:41:55.603781",
     "exception": false,
     "start_time": "2025-04-08T03:41:43.501024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "\n",
    "import math, random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import label, find_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18751ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:55.611037Z",
     "iopub.status.busy": "2025-04-08T03:41:55.610536Z",
     "iopub.status.idle": "2025-04-08T03:41:55.620351Z",
     "shell.execute_reply": "2025-04-08T03:41:55.619545Z"
    },
    "papermill": {
     "duration": 0.014716,
     "end_time": "2025-04-08T03:41:55.621700",
     "exception": false,
     "start_time": "2025-04-08T03:41:55.606984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sample_CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sample_CNN_model, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # Replaces conv4\n",
    "        # Fully Connected Layers\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128, 512)\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Output: 160x160\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Output: 80x80\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # Output: 40x40\n",
    "        x = self.adaptive_pool(x)  # Output: 1x1x128\n",
    "        x = x.view(x.size(0), -1)  # Flatten to 128\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Proper weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb540d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:55.628470Z",
     "iopub.status.busy": "2025-04-08T03:41:55.628206Z",
     "iopub.status.idle": "2025-04-08T03:41:55.641733Z",
     "shell.execute_reply": "2025-04-08T03:41:55.640875Z"
    },
    "papermill": {
     "duration": 0.018405,
     "end_time": "2025-04-08T03:41:55.643087",
     "exception": false,
     "start_time": "2025-04-08T03:41:55.624682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class custom_dataset():\n",
    "    def __init__(self,folder_path=None,transform=None, output_class=0):\n",
    "        self.image_paths=[]\n",
    "        self.output_classes=[]\n",
    "        self.transform=transform\n",
    "        if (output_class==0):\n",
    "            self.o=\"Diverticulosis\"\n",
    "        elif (output_class==1):\n",
    "            self.o=\"Neoplasm\"\n",
    "        elif (output_class==2):\n",
    "            self.o=\"Peritonitis\"\n",
    "        else:\n",
    "            self.o=\"Ureters\"\n",
    "        if (folder_path!=None):\n",
    "            for center_name_zipp in os.listdir(folder_path):\n",
    "                for center_name in os.listdir(os.path.join(folder_path,center_name_zipp)):\n",
    "                    for category_name in os.listdir(os.path.join(folder_path,center_name_zipp,center_name)):\n",
    "                        if (category_name == self.o):\n",
    "                            for image_name in os.listdir(os.path.join(folder_path,center_name_zipp,center_name,category_name)):\n",
    "                                self.image_paths.append(os.path.join(folder_path,center_name_zipp,center_name,category_name,image_name))\n",
    "                                self.output_classes.append(output_class)\n",
    "\n",
    "    \n",
    "\n",
    "            # # Zip the lists together and convert to a list of pairs\n",
    "            # combined = list(zip(self.image_paths, self.output_classes))\n",
    "\n",
    "            # # Shuffle the combined list\n",
    "            # random.shuffle(combined)\n",
    "\n",
    "            # # Unzip the combined s back into two lists\n",
    "            # self.image_paths, self.output_classes = zip(*combined)\n",
    "\n",
    "            # # Convert back to list type\n",
    "            # self.image_paths = list(self.image_paths)\n",
    "            # self.output_classes = list(self.output_classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "    # def bias_field_correction(self, channel_np):\n",
    "    #     \"\"\"\n",
    "    #     Apply bias field correction to a single-channel image.\n",
    "    #     \"\"\"\n",
    "    #     sitk_image = sitk.GetImageFromArray(channel_np)\n",
    "    #     # Create a mask using Otsu thresholding\n",
    "    #     mask = sitk.OtsuThreshold(sitk_image, 0, 1, 200)\n",
    "    #     corrected = sitk.N4BiasFieldCorrection(sitk_image, mask)\n",
    "    #     corrected_np = sitk.GetArrayFromImage(corrected)\n",
    "    #     return corrected_np\n",
    "\n",
    "    # def crop_to_white_blob(self, image_np):\n",
    "    #     \"\"\"\n",
    "    #     Crop the image to the bounding box of the connected component \n",
    "    #     (from the white blob) that contains the center of the image.\n",
    "    #     \"\"\"\n",
    "    #     # Convert first three channels (RGB) to grayscale by averaging\n",
    "    #     gray = np.mean(image_np[:, :, :3], axis=2)\n",
    "    #     # Create a binary mask; adjust threshold as needed for your data\n",
    "    #     binary = gray > 200\n",
    "\n",
    "    #     # Label connected regions and find bounding boxes\n",
    "    #     labeled, num_features = label(binary)\n",
    "    #     center_y, center_x = gray.shape[0] // 2, gray.shape[1] // 2\n",
    "    #     selected_bbox = None\n",
    "    #     objects = find_objects(labeled)\n",
    "    #     for i, slice_tuple in enumerate(objects, start=1):\n",
    "    #         y_slice, x_slice = slice_tuple\n",
    "    #         # Check if the image center lies within the component's bounding box\n",
    "    #         if (y_slice.start <= center_y < y_slice.stop) and (x_slice.start <= center_x < x_slice.stop):\n",
    "    #             selected_bbox = slice_tuple\n",
    "    #             break\n",
    "\n",
    "    #     if selected_bbox is not None:\n",
    "    #         y_slice, x_slice = selected_bbox\n",
    "    #         cropped = image_np[y_slice, x_slice, :]\n",
    "    #         return cropped\n",
    "    #     else:\n",
    "    #         # If no white blob is detected near the center, return the original image\n",
    "    #         return image_np\n",
    "\n",
    "    # def zscore_normalize(self, image_np):\n",
    "    #     \"\"\"\n",
    "    #     Apply per-channel z-score normalization.\n",
    "    #     \"\"\"\n",
    "    #     # Process each channel independently\n",
    "    #     for c in range(image_np.shape[2]):\n",
    "    #         channel = image_np[:, :, c]\n",
    "    #         mean = channel.mean()\n",
    "    #         std = channel.std()\n",
    "    #         if std > 0:\n",
    "    #             image_np[:, :, c] = (channel - mean) / std\n",
    "    #         else:\n",
    "    #             image_np[:, :, c] = channel - mean\n",
    "    #     return image_np\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the preprocessed image (assumed to already have the desired size and channels)\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        \n",
    "        # Optionally apply additional transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Convert image to a numpy array and then to a torch tensor with shape (C, H, W)\n",
    "            image_np = np.array(image)\n",
    "            image = torch.from_numpy(image_np.transpose(2, 0, 1))\n",
    "        \n",
    "        return image, self.output_classes[idx]\n",
    "\n",
    "\n",
    "    def take_out_items(self, ratio):\n",
    "\n",
    "        indices_label0 = [i for i, label in enumerate(self.output_classes) if label == 0]\n",
    "        indices_label1 = [i for i, label in enumerate(self.output_classes) if label == 1]\n",
    "        indices_label2 = [i for i, label in enumerate(self.output_classes) if label == 2]\n",
    "        indices_label3 = [i for i, label in enumerate(self.output_classes) if label == 3]\n",
    "\n",
    "        num_to_remove_0 = math.floor(len(indices_label0) * ratio)\n",
    "        num_to_remove_1 = math.floor(len(indices_label1) * ratio)\n",
    "        num_to_remove_2 = math.floor(len(indices_label2) * ratio)\n",
    "        num_to_remove_3 = math.floor(len(indices_label3) * ratio)\n",
    "\n",
    "        selected_indices_0 = random.sample(indices_label0, num_to_remove_0) if num_to_remove_0 > 0 else []\n",
    "        selected_indices_1 = random.sample(indices_label1, num_to_remove_1) if num_to_remove_1 > 0 else []\n",
    "        selected_indices_2 = random.sample(indices_label2, num_to_remove_2) if num_to_remove_2 > 0 else []\n",
    "        selected_indices_3 = random.sample(indices_label3, num_to_remove_3) if num_to_remove_3 > 0 else []\n",
    "\n",
    "        selected_indices = set(selected_indices_0 + selected_indices_1 + selected_indices_2 + selected_indices_3)\n",
    "\n",
    "        removed_image_paths = [self.image_paths[i] for i in selected_indices]\n",
    "        removed_labels = [self.output_classes[i] for i in selected_indices]\n",
    "\n",
    "        new_image_paths = []\n",
    "        new_output_classes = []\n",
    "        for idx, (img_path, label) in enumerate(zip(self.image_paths, self.output_classes)):\n",
    "            if idx not in selected_indices:\n",
    "                new_image_paths.append(img_path)\n",
    "                new_output_classes.append(label)\n",
    "\n",
    "        self.image_paths = new_image_paths\n",
    "        self.output_classes = new_output_classes\n",
    "\n",
    "        return removed_image_paths, removed_labels\n",
    "\n",
    "    def add_items(self, list_of_image_paths,list_of_labels):\n",
    "        self.image_paths.extend(list_of_image_paths)\n",
    "        self.output_classes.extend(list_of_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79259e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T03:41:55.650403Z",
     "iopub.status.busy": "2025-04-08T03:41:55.650120Z",
     "iopub.status.idle": "2025-04-08T10:49:12.605744Z",
     "shell.execute_reply": "2025-04-08T10:49:12.604707Z"
    },
    "papermill": {
     "duration": 25636.961455,
     "end_time": "2025-04-08T10:49:12.607685",
     "exception": false,
     "start_time": "2025-04-08T03:41:55.646230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of batches across dataloaders:  32\n",
      "\n",
      "=== Starting Training with: Test Ratio=0.2, Batch Size=100, Rounds=10, Epochs=2, LR=0.001 ===\n",
      "\n",
      "Round 1/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  10.049132823944092\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  10.911068677902222\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  10.32063102722168\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  10.579951405525208\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 1 Metrics - Loss: 1.3991 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 2/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  24.651308059692383\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  28.079524993896484\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  25.172038793563843\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  22.41925811767578\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 2 Metrics - Loss: 1.4228 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 3/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  31.92531156539917\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  37.93282890319824\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  35.721137046813965\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  40.955976486206055\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 3 Metrics - Loss: 1.3963 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 4/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  32.38293719291687\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  49.94266891479492\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  37.31967878341675\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  45.52881956100464\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 4 Metrics - Loss: 1.3926 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 5/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  14.041963934898376\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  16.250727653503418\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  17.79294776916504\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  9.881380081176758\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 5 Metrics - Loss: 1.3853 | Accuracy: 0.4113 | Precision: 0.2499 | Recall: 0.4113 | F1: 0.2962       \n",
      "\n",
      "Round 6/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  15.993218064308167\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  18.89664912223816\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  17.712362051010132\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  16.546308279037476\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 6 Metrics - Loss: 1.3868 | Accuracy: 0.2550 | Precision: 0.1232 | Recall: 0.2550 | F1: 0.1265       \n",
      "\n",
      "Round 7/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  65.1288537979126\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  75.57932376861572\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  75.08163022994995\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  82.7342176437378\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 7 Metrics - Loss: 1.3932 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 8/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  89.77294921875\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  13.659799337387085\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  75.79473495483398\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  24.5741605758667\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 8 Metrics - Loss: 1.3912 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 9/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  12.228420495986938\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  41.0999550819397\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  80.3218641281128\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  55.92469835281372\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 9 Metrics - Loss: 1.3884 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n",
      "\n",
      "Round 10/10:\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  20.404287099838257\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  28.81834650039673\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  60.62307643890381\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############### LOCAL MODEL LOGS ############\n",
      "After_Training Local Model:\n",
      "avg_loss:  41.19856405258179\n",
      "Accuracy:  0.25\n",
      "precision:  0.0625\n",
      "recall:  0.25\n",
      "############## GLOBAL MODEL LOGS ##############\n",
      "  Round 10 Metrics - Loss: 1.3893 | Accuracy: 0.2500 | Precision: 0.0625 | Recall: 0.2500 | F1: 0.1000       \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "\n",
    "# ====================== METRICS & PLOTTING ======================\n",
    "def test_global_model(global_model, test_dataloader):\n",
    "    \"\"\"Returns test loss, accuracy, precision, recall, F1\"\"\"\n",
    "    global_model.eval()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(test_dataloader):\n",
    "            outputs = global_model(images)\n",
    "            # print(\"OUTPUTS:\")\n",
    "            # print(outputs)\n",
    "            # print(\"LABELS:\")\n",
    "            # print(labels)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    # print(\"The Accuracy of local model after training: \",accuracy)\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def plot_learning_curves(metrics_history, hyperparams):\n",
    "    \"\"\"Plots metrics vs communication rounds for a single hyperparameter configuration\"\"\"\n",
    "    rounds = list(range(1, len(metrics_history['loss'])+1))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.suptitle(f\"Test Ratio: {hyperparams['test_ratio']} | Batch Size: {hyperparams['batch_size']}\\n\"\n",
    "                 f\"Rounds: {hyperparams['num_rounds']} | Epochs: {hyperparams['num_epochs']} | LR: {hyperparams['learning_rate']}\", \n",
    "                 y=1.02)\n",
    "    \n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall', 'f1']\n",
    "    titles = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles), 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        plt.plot(rounds, metrics_history[metric], marker='o')\n",
    "        plt.xlabel('Communication Round')\n",
    "        plt.ylabel(title)\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/kaggle/working/learning_curves_ratio_{hyperparams['test_ratio']}_bs_{hyperparams['batch_size']}_rounds_{hyperparams['num_rounds']}_epochs_{hyperparams['num_epochs']}_lr_{hyperparams['learning_rate']}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_hyperparameter_comparisons(all_results):\n",
    "    \"\"\"Generates plots comparing metrics across different hyperparameters\"\"\"\n",
    "    hyperparams = ['test_ratio', 'batch_size', 'num_rounds', 'num_epochs', 'learning_rate']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'loss']\n",
    "    \n",
    "    for hp in hyperparams:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for metric in metrics:\n",
    "            x = [res['hyperparams'][hp] for res in all_results]\n",
    "            y = [res['final_'+metric] for res in all_results]\n",
    "            plt.scatter(x, y, label=metric, alpha=0.6)\n",
    "        \n",
    "        plt.xlabel(hp)\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.title(f'Impact of {hp} on Metrics')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"/kaggle/working/hyperparam_{hp}_comparison.png\")\n",
    "        plt.close()\n",
    "\n",
    "# ====================== FEDERATED LEARNING CORE ======================\n",
    "def train_local_model(global_model, num_epochs, train_dataloader, test_dataloader, learning_rate):\n",
    "\n",
    "    print(\"############### LOCAL MODEL LOGS ############\")\n",
    "    local_model = copy.deepcopy(global_model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(local_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Use a learning rate scheduler to prevent getting stuck\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "    \n",
    "    local_model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        for images, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        val_loss, val_acc, _, _, _ = test_global_model(local_model, test_dataloader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    avg_loss, accuracy, precision, recall, f1=test_global_model(local_model,test_dataloader)\n",
    "    print(\"After_Training Local Model:\")\n",
    "    print(\"avg_loss: \",avg_loss)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    \n",
    "    return local_model.state_dict()\n",
    "\n",
    "def federated_learning_algo(model, train_dataloaders, test_dataloader, num_rounds, num_epochs, learning_rate, hyperparams):\n",
    "    global_model = copy.deepcopy(model)\n",
    "    total_clients = len(train_dataloaders)\n",
    "    total_batches_across_dataloaders=sum([len(train_dataloader) for train_dataloader in train_dataloaders])\n",
    "    print(\"Total Number of batches across dataloaders: \",total_batches_across_dataloaders)\n",
    "    metrics_history = {'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    \n",
    "    print(f\"\\n=== Starting Training with: Test Ratio={hyperparams['test_ratio']}, Batch Size={hyperparams['batch_size']}, \"\n",
    "          f\"Rounds={num_rounds}, Epochs={num_epochs}, LR={learning_rate} ===\")\n",
    "\n",
    "    client_optimizers = [\n",
    "        torch.optim.Adam(global_model.parameters(), lr=learning_rate)\n",
    "        for _ in range(len(train_dataloaders))\n",
    "    ]\n",
    "    \n",
    "    for round in range(1, num_rounds+1):\n",
    "        print(f\"\\nRound {round}/{num_rounds}:\")\n",
    "        \n",
    "        # Local Training\n",
    "        client_weights = []\n",
    "        for client_id, (dataloader, optimizer) in enumerate(zip(train_dataloaders, client_optimizers), 1):\n",
    "            print(f\"  Client {client_id} training...\", end='\\r')\n",
    "            weights = train_local_model(global_model, num_epochs, dataloader, test_dataloader, learning_rate)\n",
    "            client_weights.append(weights)\n",
    "        \n",
    "        # Aggregation (Federated Averaging)\n",
    "        global_weights = {}\n",
    "        for key in client_weights[0].keys():\n",
    "            for client, train_dataloader in zip(client_weights, train_dataloaders):\n",
    "                if (key not in global_weights.keys()):\n",
    "                    global_weights[key] = (len(train_dataloader)/total_batches_across_dataloaders)*client[key]\n",
    "                    # print(\"ratio: \",(len(train_dataloader)/total_batches_across_dataloaders))\n",
    "                else:\n",
    "                    global_weights[key] += (len(train_dataloader)/total_batches_across_dataloaders)*client[key]                \n",
    "                    # print(\"ratio: \",(len(train_dataloader)/total_batches_across_dataloaders))\n",
    "                    \n",
    "        global_model.load_state_dict(global_weights)\n",
    "        \n",
    "        # Testing\n",
    "        test_loss, acc, prec, rec, f1 = test_global_model(global_model, test_dataloader)\n",
    "        metrics_history['loss'].append(test_loss)\n",
    "        metrics_history['accuracy'].append(acc)\n",
    "        metrics_history['precision'].append(prec)\n",
    "        metrics_history['recall'].append(rec)\n",
    "        metrics_history['f1'].append(f1)\n",
    "\n",
    "        print(\"############## GLOBAL MODEL LOGS ##############\")\n",
    "        print(f\"  Round {round} Metrics - Loss: {test_loss:.4f} | Accuracy: {acc:.4f} | \"\n",
    "              f\"Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}       \")\n",
    "    \n",
    "    # Save learning curves for this configuration\n",
    "    plot_learning_curves(metrics_history, hyperparams)\n",
    "\n",
    "    torch.save(global_model,\"/kaggle/working/\"+str(hyperparams[\"test_ratio\"])+\"_\"+str(hyperparams[\"batch_size\"])+\"_\"+str(hyperparams[\"num_rounds\"])+\"_\"+str(hyperparams[\"num_epochs\"])+\"_\"+str(hyperparams[\"learning_rate\"])+\".pth\")\n",
    "    torch.save(global_model.state_dict(),\"/kaggle/working/\"+str(hyperparams[\"test_ratio\"])+\"_\"+str(hyperparams[\"batch_size\"])+\"_\"+str(hyperparams[\"num_rounds\"])+\"_\"+str(hyperparams[\"num_epochs\"])+\"_\"+str(hyperparams[\"learning_rate\"])+\"_state_dict.pth\")\n",
    "    \n",
    "    # Return final metrics for hyperparameter comparison\n",
    "    return {\n",
    "        'hyperparams': hyperparams,\n",
    "        'final_accuracy': metrics_history['accuracy'][-1],\n",
    "        'final_precision': metrics_history['precision'][-1],\n",
    "        'final_recall': metrics_history['recall'][-1],\n",
    "        'final_f1': metrics_history['f1'][-1],\n",
    "        'final_loss': metrics_history['loss'][-1]\n",
    "    }\n",
    "\n",
    "# ====================== MAIN EXECUTION ======================\n",
    "\n",
    "    \n",
    "# Assume model and datasets are predefined\n",
    "model = sample_CNN_model()  # Your model definition\n",
    "\n",
    "# For training data (with augmentations)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# For validation/test data (no augmentations)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "center_datasets = [custom_dataset(folder_path=\"/kaggle/input/new-centers\",transform=train_transforms,output_class=0),custom_dataset(folder_path=\"/kaggle/input/new-centers\",transform=train_transforms,output_class=1), custom_dataset(folder_path=\"/kaggle/input/new-centers\",transform=train_transforms,output_class=2), custom_dataset(folder_path=\"/kaggle/input/new-centers\",transform=train_transforms,output_class=3)]  # Your central datasets\n",
    "\n",
    "# Hyperparameter Search Space\n",
    "test_ratios = [0.2]\n",
    "batch_sizes = [100]\n",
    "num_rounds_list = [10]\n",
    "num_epochs_list = [2]\n",
    "learning_rates = [0.001] #,0.00007,0.0001,0.0007\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for test_ratio in test_ratios:\n",
    "    \n",
    "    # Dataset preparation\n",
    "    to_put_image_paths=[]\n",
    "    to_put_image_labels=[]\n",
    "    for center_dataset in center_datasets:\n",
    "        to_append_image_paths,to_append_image_labels=center_dataset.take_out_items(test_ratio)\n",
    "        to_put_image_paths.extend(to_append_image_paths)\n",
    "        to_put_image_labels.extend(to_append_image_labels)\n",
    "    test_dataset=custom_dataset(transform=test_transforms)#Here the folder path is None so that it makes an empty dataset\n",
    "    test_dataset.add_items(to_put_image_paths,to_put_image_labels)\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        train_dataloaders = [DataLoader(center_dataset, batch_size=batch_size,shuffle=True) for center_dataset in center_datasets]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n",
    "        \n",
    "        for num_rounds in num_rounds_list:\n",
    "            for num_epochs in num_epochs_list:\n",
    "                for lr in learning_rates:\n",
    "                    hyperparams = {\n",
    "                        'test_ratio': test_ratio,\n",
    "                        'batch_size': batch_size,\n",
    "                        'num_rounds': num_rounds,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'learning_rate': lr\n",
    "                    }\n",
    "                    \n",
    "                    # Run federated learning\n",
    "                    result = federated_learning_algo(\n",
    "                        model, train_dataloaders, test_dataloader, \n",
    "                        num_rounds, num_epochs, lr, hyperparams\n",
    "                    )\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "\n",
    "# Generate hyperparameter comparison plots\n",
    "plot_hyperparameter_comparisons(all_results)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7046228,
     "sourceId": 11271844,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25668.536007,
   "end_time": "2025-04-08T10:49:15.198732",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-08T03:41:26.662725",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
